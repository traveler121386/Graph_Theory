"""
ç¤¾åŒºæ£€æµ‹æ¨¡å—
ä½¿ç”¨ Louvain ç®—æ³•è¿›è¡Œç¤¾åŒºæ£€æµ‹å’Œåˆ†æ
"""

import networkx as nx
import pandas as pd
from typing import Dict, List, Tuple
import numpy as np

try:
    from networkx.algorithms import community
    import networkx.algorithms.community as nx_community
except ImportError:
    pass


class CommunityDetector:
    """ç¤¾åŒºæ£€æµ‹å™¨"""
    
    def __init__(self, G: nx.Graph):
        """
        åˆå§‹åŒ–ç¤¾åŒºæ£€æµ‹å™¨
        
        Args:
            G: è¾“å…¥çš„ç½‘ç»œå›¾
        """
        self.G = G
        self.communities = None
        self.community_map = {}
        self.analysis_results = {}
    
    def detect_communities_louvain(self) -> Dict[int, set]:
        """
        ä½¿ç”¨ Louvain ç®—æ³•è¿›è¡Œç¤¾åŒºæ£€æµ‹
        
        Louvain ç®—æ³•è¯´æ˜ï¼š
        - æ˜¯ä¸€ç§è´ªå¿ƒä¼˜åŒ–ç®—æ³•ï¼Œé€šè¿‡æœ€å¤§åŒ–æ¨¡å—åº¦æ¥æ£€æµ‹ç¤¾åŒº
        - ä¼˜ç‚¹ï¼šé€Ÿåº¦å¿«ã€ç²¾åº¦é«˜ã€å¯æ‰©å±•æ€§å¥½
        - é€‚ç”¨äºå¤§è§„æ¨¡ç½‘ç»œ
        
        Returns:
            ç¤¾åŒºå­—å…¸ {ç¤¾åŒºID: èŠ‚ç‚¹é›†åˆ}
        """
        print("\n" + "="*60)
        print("ğŸ” ç¤¾åŒºç»“æ„æ£€æµ‹ - Louvain ç®—æ³•")
        print("="*60)
        
        print("\næ­£åœ¨æ‰§è¡Œ Louvain ç®—æ³•...")
        
        try:
            # å°è¯•ä½¿ç”¨ python-louvain åº“
            try:
                import community as community_louvain
                partition = community_louvain.best_partition(self.G)
                
                # è½¬æ¢ä¸ºç¤¾åŒºé›†åˆæ ¼å¼
                communities = {}
                for node, comm_id in partition.items():
                    if comm_id not in communities:
                        communities[comm_id] = set()
                    communities[comm_id].add(node)
                
            except ImportError:
                # å¦‚æœæ²¡æœ‰ python-louvainï¼Œä½¿ç”¨ NetworkX çš„ Louvain å®ç°
                print("ä½¿ç”¨ NetworkX å†…ç½®çš„ Louvain ç®—æ³•...")
                communities_generator = nx_community.louvain_communities(self.G, seed=42)
                communities = {i: comm for i, comm in enumerate(communities_generator)}
        
        except Exception as e:
            print(f"Louvain ç®—æ³•æ‰§è¡Œå¤±è´¥: {e}")
            print("ä½¿ç”¨ Girvan-Newman ç®—æ³•ä½œä¸ºå¤‡é€‰...")
            communities = self.detect_communities_girvan_newman()
        
        self.communities = communities
        self._build_community_map()
        
        print(f"\nâœ“ ç¤¾åŒºæ£€æµ‹å®Œæˆ")
        print(f"  - æ£€æµ‹åˆ°çš„ç¤¾åŒºæ•°: {len(communities)}")
        
        return communities
    
    def detect_communities_girvan_newman(self) -> Dict[int, set]:
        """
        ä½¿ç”¨ Girvan-Newman ç®—æ³•è¿›è¡Œç¤¾åŒºæ£€æµ‹ï¼ˆå¤‡é€‰æ–¹æ¡ˆï¼‰
        
        Girvan-Newman ç®—æ³•è¯´æ˜ï¼š
        - åŸºäºè¾¹çš„ä»‹æ•°ä¸­å¿ƒæ€§ï¼Œè¿­ä»£åˆ é™¤ä»‹æ•°æœ€é«˜çš„è¾¹
        - ä¼˜ç‚¹ï¼šç†è®ºåŸºç¡€æ‰å®ï¼Œç»“æœå¯è§£é‡Šæ€§å¼º
        - ç¼ºç‚¹ï¼šè®¡ç®—å¤æ‚åº¦è¾ƒé«˜ï¼Œä¸é€‚åˆå¤§è§„æ¨¡ç½‘ç»œ
        
        Returns:
            ç¤¾åŒºå­—å…¸ {ç¤¾åŒºID: èŠ‚ç‚¹é›†åˆ}
        """
        print("\næ­£åœ¨æ‰§è¡Œ Girvan-Newman ç®—æ³•...")
        
        # è·å–æœ€ä¼˜çš„ç¤¾åŒºåˆ’åˆ†
        communities_generator = nx_community.girvan_newman(self.G)
        
        # è®¡ç®—æ¨¡å—åº¦ï¼Œæ‰¾åˆ°æœ€ä¼˜çš„ç¤¾åŒºæ•°
        best_modularity = -1
        best_communities = None
        
        for communities in communities_generator:
            modularity = nx_community.modularity(self.G, communities)
            if modularity > best_modularity:
                best_modularity = modularity
                best_communities = communities
        
        # è½¬æ¢ä¸ºå­—å…¸æ ¼å¼
        communities_dict = {i: comm for i, comm in enumerate(best_communities)}
        
        self.communities = communities_dict
        self._build_community_map()
        
        print(f"âœ“ Girvan-Newman ç®—æ³•å®Œæˆ")
        print(f"  - æ£€æµ‹åˆ°çš„ç¤¾åŒºæ•°: {len(communities_dict)}")
        print(f"  - æ¨¡å—åº¦: {best_modularity:.4f}")
        
        return communities_dict
    
    def _build_community_map(self):
        """æ„å»ºèŠ‚ç‚¹åˆ°ç¤¾åŒºçš„æ˜ å°„"""
        self.community_map = {}
        for comm_id, nodes in self.communities.items():
            for node in nodes:
                self.community_map[node] = comm_id
    
    def analyze_community_structure(self) -> pd.DataFrame:
        """
        åˆ†æç¤¾åŒºç»“æ„ç‰¹å¾
        
        Returns:
            ç¤¾åŒºç»Ÿè®¡ä¿¡æ¯ DataFrame
        """
        print("\n" + "-"*60)
        print("ğŸ“Š ç¤¾åŒºç»“æ„ç‰¹å¾åˆ†æ")
        print("-"*60)
        
        community_stats = []
        
        for comm_id, nodes in self.communities.items():
            # åˆ›å»ºç¤¾åŒºå­å›¾
            subgraph = self.G.subgraph(nodes).copy()
            
            # è®¡ç®—ç¤¾åŒºå†…éƒ¨æŒ‡æ ‡
            n_nodes = len(nodes)
            n_edges = subgraph.number_of_edges()
            
            # å†…éƒ¨è¾¹æ•°å’Œå¤–éƒ¨è¾¹æ•°
            internal_edges = n_edges
            external_edges = 0
            for node in nodes:
                for neighbor in self.G.neighbors(node):
                    if neighbor not in nodes:
                        external_edges += 1
            
            # ç¤¾åŒºå¯†åº¦
            if n_nodes > 1:
                max_edges = n_nodes * (n_nodes - 1) / 2
                density = internal_edges / max_edges if max_edges > 0 else 0
            else:
                density = 0
            
            # å¹³å‡èšç±»ç³»æ•°
            if n_nodes > 1:
                avg_clustering = nx.average_clustering(subgraph)
            else:
                avg_clustering = 0
            
            # ç¤¾åŒºå‡èšåŠ› = å†…éƒ¨è¾¹æ•° / (å†…éƒ¨è¾¹æ•° + å¤–éƒ¨è¾¹æ•°)
            cohesion = internal_edges / (internal_edges + external_edges) if (internal_edges + external_edges) > 0 else 0
            
            community_stats.append({
                'ç¤¾åŒºID': f'C{comm_id}',
                'èŠ‚ç‚¹æ•°': n_nodes,
                'å†…éƒ¨è¾¹æ•°': internal_edges,
                'å¤–éƒ¨è¾¹æ•°': external_edges,
                'ç¤¾åŒºå¯†åº¦': density,
                'å¹³å‡èšç±»ç³»æ•°': avg_clustering,
                'ç¤¾åŒºå‡èšåŠ›': cohesion,
                'ä»£è¡¨èŠ‚ç‚¹': list(nodes)[:3]  # å‰3ä¸ªèŠ‚ç‚¹ä½œä¸ºä»£è¡¨
            })
        
        stats_df = pd.DataFrame(community_stats)
        stats_df = stats_df.sort_values('èŠ‚ç‚¹æ•°', ascending=False)
        
        self.analysis_results['community_stats'] = stats_df
        
        # æ‰“å°ç¤¾åŒºç»Ÿè®¡
        print("\nç¤¾åŒºç»Ÿè®¡ä¿¡æ¯:")
        print("-"*60)
        for idx, row in stats_df.iterrows():
            print(f"\n{row['ç¤¾åŒºID']}:")
            print(f"  èŠ‚ç‚¹æ•°: {row['èŠ‚ç‚¹æ•°']}")
            print(f"  å†…éƒ¨è¾¹æ•°: {row['å†…éƒ¨è¾¹æ•°']}")
            print(f"  å¤–éƒ¨è¾¹æ•°: {row['å¤–éƒ¨è¾¹æ•°']}")
            print(f"  ç¤¾åŒºå¯†åº¦: {row['ç¤¾åŒºå¯†åº¦']:.4f}")
            print(f"  å¹³å‡èšç±»ç³»æ•°: {row['å¹³å‡èšç±»ç³»æ•°']:.4f}")
            print(f"  ç¤¾åŒºå‡èšåŠ›: {row['ç¤¾åŒºå‡èšåŠ›']:.4f}")
        
        return stats_df
    
    def analyze_community_meaning(self, stats_df: pd.DataFrame) -> str:
        """
        åˆ†æç¤¾åŒºçš„å«ä¹‰å’Œç‰¹å¾
        
        Args:
            stats_df: ç¤¾åŒºç»Ÿè®¡ DataFrame
        
        Returns:
            åˆ†æè¯´æ˜æ–‡æœ¬
        """
        print("\n" + "-"*60)
        print("ğŸ’¡ ç¤¾åŒºåˆ’åˆ†ç»“æœåŠå…¶æ„ä¹‰")
        print("-"*60)
        
        analysis = []
        
        analysis.append(f"\nã€ç¤¾åŒºæ•°é‡ã€‘")
        analysis.append(f"æ£€æµ‹åˆ° {len(self.communities)} ä¸ªç¤¾åŒº")
        analysis.append(f"è¿™è¡¨æ˜ç¤¾äº¤ç½‘ç»œä¸­å­˜åœ¨æ˜æ˜¾çš„ç¤¾å›¢ç»“æ„")
        
        # åˆ†ææœ€å¤§ç¤¾åŒº
        largest_comm = stats_df.iloc[0]
        analysis.append(f"\nã€æœ€å¤§ç¤¾åŒºã€‘")
        analysis.append(f"ç¤¾åŒº: {largest_comm['ç¤¾åŒºID']}")
        analysis.append(f"èŠ‚ç‚¹æ•°: {largest_comm['èŠ‚ç‚¹æ•°']} ({largest_comm['èŠ‚ç‚¹æ•°']/self.G.number_of_nodes()*100:.1f}%)")
        analysis.append(f"ç¤¾åŒºå¯†åº¦: {largest_comm['ç¤¾åŒºå¯†åº¦']:.4f}")
        analysis.append(f"å«ä¹‰: è¿™æ˜¯ç½‘ç»œä¸­æœ€å¤§çš„ç”¨æˆ·ç¾¤ä½“ï¼Œå¯èƒ½ä»£è¡¨ä¸€ä¸ªä¸»è¦çš„å…´è¶£åœˆå­æˆ–ç¤¾äº¤ç¾¤ä½“")
        
        # åˆ†æç¤¾åŒºå‡èšåŠ›
        avg_cohesion = stats_df['ç¤¾åŒºå‡èšåŠ›'].mean()
        analysis.append(f"\nã€ç¤¾åŒºå‡èšåŠ›ã€‘")
        analysis.append(f"å¹³å‡ç¤¾åŒºå‡èšåŠ›: {avg_cohesion:.4f}")
        if avg_cohesion > 0.5:
            analysis.append(f"è¯´æ˜: ç¤¾åŒºå†…éƒ¨è¿æ¥ç´§å¯†ï¼Œç¤¾åŒºé—´è¿æ¥è¾ƒå°‘")
            analysis.append(f"      è¿™æ˜¯è‰¯å¥½çš„ç¤¾åŒºåˆ’åˆ†ï¼Œè¡¨æ˜ç”¨æˆ·ç¡®å®èšé›†åœ¨ä¸åŒçš„ç¾¤ä½“ä¸­")
        else:
            analysis.append(f"è¯´æ˜: ç¤¾åŒºé—´å­˜åœ¨è¾ƒå¤šè¿æ¥ï¼Œå¯èƒ½å­˜åœ¨è·¨ç¤¾åŒºçš„å…³é”®ç”¨æˆ·")
        
        # åˆ†æç¤¾åŒºå¤šæ ·æ€§
        size_std = stats_df['èŠ‚ç‚¹æ•°'].std()
        analysis.append(f"\nã€ç¤¾åŒºå¤šæ ·æ€§ã€‘")
        analysis.append(f"ç¤¾åŒºå¤§å°æ ‡å‡†å·®: {size_std:.2f}")
        if size_std > 20:
            analysis.append(f"è¯´æ˜: ç¤¾åŒºå¤§å°å·®å¼‚è¾ƒå¤§ï¼Œç½‘ç»œä¸­æ—¢æœ‰å¤§å‹ç¤¾å›¢ä¹Ÿæœ‰å°å‹ç¤¾å›¢")
        else:
            analysis.append(f"è¯´æ˜: ç¤¾åŒºå¤§å°ç›¸å¯¹å‡åŒ€")
        
        # åˆ†æç¤¾åŒºé—´çš„è¿æ¥
        analysis.append(f"\nã€ç¤¾åŒºé—´è¿æ¥ã€‘")
        total_external = stats_df['å¤–éƒ¨è¾¹æ•°'].sum()
        total_internal = stats_df['å†…éƒ¨è¾¹æ•°'].sum()
        external_ratio = total_external / (total_internal + total_external) if (total_internal + total_external) > 0 else 0
        analysis.append(f"å†…éƒ¨è¾¹æ•°å æ¯”: {(1-external_ratio)*100:.1f}%")
        analysis.append(f"å¤–éƒ¨è¾¹æ•°å æ¯”: {external_ratio*100:.1f}%")
        analysis.append(f"è¯´æ˜: å¤–éƒ¨è¾¹æ•°å æ¯”è¶Šä½ï¼Œç¤¾åŒºåˆ’åˆ†è¶Šæ¸…æ™°")
        
        result_text = "\n".join(analysis)
        print(result_text)
        
        return result_text
    
    def get_community_for_node(self, node: str) -> int:
        """
        è·å–èŠ‚ç‚¹æ‰€å±çš„ç¤¾åŒº
        
        Args:
            node: èŠ‚ç‚¹åç§°
        
        Returns:
            ç¤¾åŒºID
        """
        return self.community_map.get(node, -1)
    
    def run_all_detection(self) -> Dict:
        """
        è¿è¡Œæ‰€æœ‰ç¤¾åŒºæ£€æµ‹åˆ†æ
        
        Returns:
            åŒ…å«æ‰€æœ‰åˆ†æç»“æœçš„å­—å…¸
        """
        # æ£€æµ‹ç¤¾åŒº
        self.detect_communities_louvain()
        
        # åˆ†æç¤¾åŒºç»“æ„
        stats_df = self.analyze_community_structure()
        self.analyze_community_meaning(stats_df)
        
        return self.analysis_results


def main():
    """æµ‹è¯•ç¤¾åŒºæ£€æµ‹æ¨¡å—"""
    from data_generator import SocialNetworkGenerator
    
    # ç”Ÿæˆç½‘ç»œ
    generator = SocialNetworkGenerator(seed=42)
    G = generator.generate_complete_network(n_nodes=300, m=3)
    
    # æ£€æµ‹ç¤¾åŒº
    detector = CommunityDetector(G)
    results = detector.run_all_detection()
    
    print("\n" + "="*60)
    print("ç¤¾åŒºæ£€æµ‹æ¨¡å—æµ‹è¯•å®Œæˆ")
    print("="*60)


if __name__ == "__main__":
    main()

